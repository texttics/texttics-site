<!doctype html>
<html>
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KKG6C4ZW');</script>
  <!-- End Google Tag Manager -->

<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Google Analytics & Consent Mode -->
<script>
  // Define dataLayer + gtag *first*
  window.dataLayer = window.dataLayer || [];
  function gtag(){ dataLayer.push(arguments); }

  // 1) Set Consent Mode *defaults* BEFORE loading gtag.js
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied',
    'ad_user_data': 'denied',
    'ad_personalization': 'denied',
    'wait_for_update': 500
  });

  // (optional hardening)
  gtag('set', 'url_passthrough', true);
  gtag('set', 'ads_data_redaction', true);
</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-HKGZL0K924"></script>

<script>
  // 3) Initialize & configure GA4
  gtag('js', new Date());
  gtag('config', 'G-HKGZL0K924');
</script>

<!-- PyScript -->
<link rel="stylesheet" href="https://pyscript.net/releases/2024.9.1/core.css" />
<script type="module" src="https://pyscript.net/releases/2024.9.1/core.js"></script>


  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
      font: 16px/1.4 system-ui, sans-serif;
      max-width: 1400px;
      margin: 2rem auto;
      padding: 0 1rem;
      padding-bottom: 150px;
      background-color: #f9fafb;
      color: #111827;
    }
    h1 { text-align: center; color: #1f2937; }
    h2 { 
      margin-top: 2.5rem; 
      color: #1f2937;
      border-bottom: 1px solid #d1d5db;
      padding-bottom: 0.5rem;
      display: flex;
      align-items: center;
    }
    textarea { 
      width: 100%; 
      height: 220px; 
      box-sizing: border-box; 
      border: 1px solid #d1d5db;
      border-radius: 10px;
      padding: 1rem;
      font-size: 1.1rem;
      line-height: 1.5;
    }
    textarea:focus {
      outline: 2px solid #3b82f6;
      border-color: #3b82f6;
    }
    
    /* --- Main Stats Grid --- */
    .stats {
      display: grid;
      gap: .8rem;
      margin-top: 1rem;
      grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
    }
    
    .card {
      padding: 1rem;
      border: 1px solid #e5e7eb;
      border-radius: 10px;
      background: #ffffff;
      box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
      text-align: left;
    }
    .card strong {
      display: block;
      font-size: 0.9rem;
      color: #374151;
      margin-bottom: 0.25rem;
    }
    .card div {
      font-size: 1.75rem;
      font-weight: 600;
      color: #111827;
    }

    /* --- Tooltip Styles --- */
    .tooltip {
      position: relative;
      display: inline-block;
      cursor: help;
      font-size: 1rem;
      font-weight: 600;
      color: #3b82f6;
      margin-left: 8px;
    }
    .tooltip .tooltip-text {
      visibility: hidden;
      opacity: 0;
      transition: opacity 0.3s;
      width: 320px;
      background-color: #1f2937;
      color: #fff;
      text-align: left;
      font-weight: normal;
      font-size: 0.9rem;
      line-height: 1.4;
      border-radius: 6px;
      padding: 10px;
      position: absolute;
      z-index: 10;
      bottom: 125%;
      left: 50%;
      margin-left: -160px; /* Center it (half of 320px width) */
    }
    .tooltip .tooltip-text::after {
      content: "";
      position: absolute;
      top: 100%;
      left: 50%;
      margin-left: -5px;
      border-width: 5px;
      border-style: solid;
      border-color: #1f2937 transparent transparent transparent;
    }
    .tooltip:hover .tooltip-text {
      visibility: visible;
      opacity: 1;
    }

    /* --- Tab Navigation --- */
    .tabs-nav {
      display: flex;
      gap: 0.5rem;
      margin-top: 1rem;
      border-bottom: 1px solid #d1d5db;
    }
    .tab-btn {
      padding: 0.5rem 1rem;
      border: 1px solid transparent;
      border-bottom: 0;
      border-radius: 6px 6px 0 0;
      cursor: pointer;
      background: #e5e7eb;
      color: #4b5563;
      font-weight: 500;
      transition: all 0.2s;
    }
    .tab-btn:hover {
      background: #f3f4f6;
    }
    .tab-btn.active {
      background: #ffffff;
      border-color: #d1d5db;
      color: #111827;
      border-bottom: 1px solid #ffffff;
      margin-bottom: -1px;
    }
    .tab-content {
      display: none; /* Hidden by default */
      padding: 1.5rem 0.5rem;
      border: 1px solid #d1d5db;
      border-top: 0;
      border-radius: 0 0 10px 10px;
      background: #ffffff;
    }
    .tab-content.active {
      display: grid; /* Use grid when active */
    }

    /* --- Minor Stats (Tab 3) --- */
    .stats-minor {
      grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
      gap: 0.75rem;
    }
    .minor-card {
      display: grid;
      grid-template-columns: 40px 1fr 40px;
      align-items: center;
      padding: 0.5rem 0.75rem;
      background: #f9fafb;
      border: 1px solid #e5e7eb;
      border-radius: 6px;
    }
    .minor-key {
      font-weight: 700;
      font-family: monospace;
      color: #1d4ed8;
    }
    .minor-alias {
      font-size: 0.8rem;
      color: #6b7280;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }
    .minor-val {
      font-size: 1.25rem;
      font-weight: 600;
      color: #111827;
      text-align: right;
    }
    
    /* --- Toggle Switch (Module 2) --- */
    .toggle-switch {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      margin-top: 1rem;
    }
    .toggle-switch label {
      font-weight: 500;
      color: #374151;
    }
    .switch {
      position: relative;
      display: inline-block;
      width: 50px;
      height: 28px;
    }
    .switch input { 
      opacity: 0;
      width: 0;
      height: 0;
    }
    .slider {
      position: absolute;
      cursor: pointer;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background-color: #ccc;
      transition: .4s;
      border-radius: 28px;
    }
    .slider:before {
      position: absolute;
      content: "";
      height: 20px;
      width: 20px;
      left: 4px;
      bottom: 4px;
      background-color: white;
      transition: .4s;
      border-radius: 50%;
    }
    input:checked + .slider {
      background-color: #2563eb;
    }
    input:checked + .slider:before {
      transform: translateX(22px);
    }

   
    /* --- Script Stats (Module 3) --- */
    #script-stats {
      grid-template-columns: repeat(auto-fill, minmax(120px, 1fr));
    }
    
    /* Responsive */
    @media (max-width: 600px) {
      body { margin: 1rem auto; padding: 0 0.5rem; }
      h2 { font-size: 1.25rem; }
      .stats, .stats-minor {
        grid-template-columns: 1fr;
      }
      .tabs-nav {
        flex-direction: column;
        gap: 0;
      }
      .tab-btn {
        border-radius: 6px 6px 0 0;
        margin-bottom: 0;
      }
      .tab-btn.active {
        margin-bottom: -1px;
      }
      .tab-content {
        padding: 1rem 0.5rem;
      }
    }
    
  </style>
</head>
<body>
  <!-- GTM Noscript -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KKG6C4ZW"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End GTM Noscript -->

  <!-- Hidden div for Python to store state -->
  <div id="app-state" style="display: none;">{"active_tab": "summary"}</div>

  <h1>Text...tics</h1>
  <h2>Text Input</h2>  
  <textarea id="text" py-input="update_all" placeholder="Paste or type here..."></textarea>
  
  <!-- === MODULE 1: COMPREHENSIVE CHARACTER ANALYSIS === -->
  <h2>
    Comprehensive Character Analysis
    <span class="tooltip">(?)
      <span class="tooltip-text">
        Provides a detailed breakdown of all characters based on the official Unicode Standard. The analysis is presented in three layers of detail.
      </span>
    </span>
  </h2>

<div class="toggle-switch">
    <label for="analysis-mode-toggle">Filtered (Legacy)</label>
    <label class="switch">
      <input type="checkbox" id="analysis-mode-toggle" py-click="update_all" checked>
      <span class="slider"></span>
    </label>
    <label for="analysis-mode-toggle">Honest (Full Partition)</label>
  </div>

    <!-- --- New Toggle-Switch  - Grapheme Cluster (EGC) Toggle --- -->

    <div class="toggle-switch">
    <label for="unit-mode-toggle">Code Points (Raw)</label>
    <label class="switch">
      <input type="checkbox" id="unit-mode-toggle" py-click="update_all">
      <span class="slider"></span>
    </label>
    <label for="unit-mode-toggle">Graphemes (Perceived)</label>
    </div>
    
  <!-- Tab Navigation -->
  <div class="tabs-nav">
    <button id="tab-btn-summary" class="tab-btn active" py-click="select_tab">Summary</button>
    <button id="tab-btn-major" class="tab-btn" py-click="select_tab">Major Categories</button>
    <button id="tab-btn-minor" class="tab-btn" py-click="select_tab">Full Breakdown (30)</button>
  </div>
  
  <!-- Tab 1: Summary (Default) -->
  <div id="tab-summary" class="tab-content active stats">
    <!-- This content is generated by Python -->
  </div>
  
  <!-- Tab 2: Major Categories -->
  <div id="tab-major" class="tab-content stats">
    <!-- This content is generated by Python -->
  </div>

  <!-- Tab 3: Full Breakdown (30) -->
  <div id="tab-minor" class="tab-content stats stats-minor">
    <!-- This content is generated by Python -->
  </div>

  <div id="grapheme-forensics-module" style="display: none;"> <h2>
            Grapheme Forensic Analysis
            <span class="tooltip">(?)
                <span class="tooltip-text">
                    A forensic breakdown of the physical structure of the
                    "perceived characters" (graphemes) in the text.
                </span>
            </span>
        </h2>
        <div id="grapheme-forensics-stats" class="stats">
            </div>
    </div>

  <!-- === MODULE 2: TOKEN SHAPE ANALYSIS (CLASS RUNS) === -->
  <h2 id="module-2-header">
    Token Shape Analysis (Class Runs)
    <span class="tooltip">(?)
      <span class="tooltip-text">
        Performs a Run-Length Analysis to count uninterrupted sequences (or 'runs') of the same character type. (e.g., 'Hello-100%' has 4 sequences in 'Major' mode).
      </span>
    </span>
  </h2>
  
  <!-- Toggle Switch -->
  <div class="toggle-switch">
    <label for="granularity-toggle">Major Categories</label>
    <label class="switch">
      <input type="checkbox" id="granularity-toggle" py-click="update_all">
      <span class="slider"></span>
    </label>
    <label for="granularity-toggle">Minor Categories</label>
  </div>
  
  <!-- Sequence Stats Output -->
  <div id="sequence-stats" class="stats">
    <!-- This content is generated by Python -->
  </div>

  <!-- === MODULE 3: SCRIPT ANALYSIS === -->
  <h2 id="module-3-header">
    Script Analysis
    <span class="tooltip">(?)
      <span class="tooltip-text">
        Counts all characters belonging to a specific Unicode Script property (e.g., Latin, Cyrillic, Han, etc.).
      </span>
    </span>
  </h2>
  
  <!-- Script Stats Output -->
<div id="script-stats" class="stats">
        </div>

    <h2 id="module-4-header">
        Forensic Analysis
        <span class="tooltip">(?)
            <span class="tooltip-text">
                Detects "invisible" or "deceptive" characters used to manipulate text, or flags text for potential data corruption.
            </span>
        </span>
    </h2>

    <div id="forensic-stats" class="stats">
        </div>

<h2 id="module-5-header">
        Full UCD Profile (UAX #44)
        <span class="tooltip">(?)
            <span class="tooltip-text">
                A "treasure trove" of other deterministic properties from the Unicode Character Database (UAX #44), such as Block, Age, and binary properties.
            </span>
        </span>
    </h2>

    <div id="uax44-stats" class="stats">
        </div>

<h2 id="module-6-header">
        UCD Deep Scan (Python)
        <span class="tooltip">(?)
            <span class="tooltip-text">
                A full, Python-based scan of every code point to extract
                complex UCD properties like Numeric_Value and Age.
                This scan may be slower on very large texts.
            </span>
        </span>
    </h2>

    <div id="ucd-deep-scan-stats" class="stats">
        </div>
  
  <!-- === PYTHONS SCRIPT === -->
  <script type="py">

from pyscript import window, document
import json
from pyodide.ffi import create_proxy
import unicodedata

# --- 1. DEFINE CATEGORIES (Unicode Standard) ---

# Tier 3: The 30 Minor General Categories
MINOR_CATEGORIES = {
    # Letters
    "Lu": r"\p{Lu}", "Ll": r"\p{Ll}", "Lt": r"\p{Lt}", "Lm": r"\p{Lm}", "Lo": r"\p{Lo}",
    # Marks
    "Mn": r"\p{Mn}", "Mc": r"\p{Mc}", "Me": r"\p{Me}",
    # Numbers
    "Nd": r"\p{Nd}", "Nl": r"\p{Nl}", "No": r"\p{No}",
    # Punctuation
    "Pc": r"\p{Pc}", "Pd": r"\p{Pd}", "Ps": r"\p{Ps}", "Pe": r"\p{Pe}", 
    "Pi": r"\p{Pi}", "Pf": r"\p{Pf}", "Po": r"\p{Po}",
    # Symbols
    "Sm": r"\p{Sm}", "Sc": r"\p{Sc}", "Sk": r"\p{Sk}", "So": r"\p{So}",
    # Separators
    "Zs": r"\p{Zs}", "Zl": r"\p{Zl}", "Zp": r"\p{Zp}",
    # Other
    "Cc": r"\p{Cc}", "Cf": r"\p{Cf}", "Cs": r"\p{Cs}", "Co": r"\p{Co}", "Cn": r"\p{Cn}"
}

# Tier 1: Derived/Intuitive Properties
DERIVED_PROPERTIES = {
    "Emoji": r"\p{RGI_Emoji}",
    "Whitespace": r"\p{White_Space}" 
}

# New Module: Script Properties (Simplified)
SCRIPTS = {
    "Latin": r"\p{sc=Latin}",
    "Common": r"\p{sc=Common}", # Punct, symbols, etc.
    "Inherited": r"\p{sc=Inherited}" # Combining marks
}


# NEW: Forensic Properties (Module 3 Add-on)
FORENSIC_PROPERTIES = {
    "Bidi Controls": r"\p{Bidi_Control}",
    "Deprecated": r"\p{Deprecated}",                # <-- NEW
    "Noncharacter": r"\p{Noncharacter_Code_Point}", # <-- NEW
    "Ignorables (Invisible)": r"\p{Default_Ignorable_Code_Point}",
    # 'Deceptive Spaces' requires the 'v' flag for set operations
    "Deceptive Spaces": r"[\p{White_Space}&&[^ \n\r\t]]"
}

# NEW: UAX #44 'Gold' Properties (Module 5)
# These properties are supported by the JS RegExp engine
UAX44_PROPERTIES = {
    # Binary Properties
    "Dash (binary)": r"\p{Dash}",
    "Alphabetic (binary)": r"\p{Alphabetic}",

    # Script Properties (these are supported!)
    "Script: Cyrillic": r"\p{Script=Cyrillic}",
    "Script: Greek": r"\p{Script=Greek}",
    "Script: Han": r"\p{Script=Han}",
    "Script: Arabic": r"\p{Script=Arabic}",
    "Script: Hebrew": r"\p{Script=Hebrew}"
}
    
# Tier 2: The 7 Major General Categories (for Token Shape Analysis)
MAJOR_CATEGORIES_TEST = {
    "L (Letter)": window.RegExp.new(r"^\p{L}$", "u"),
    "M (Mark)": window.RegExp.new(r"^\p{M}$", "u"),
    "N (Number)": window.RegExp.new(r"^\p{N}$", "u"),
    "P (Punctuation)": window.RegExp.new(r"^\p{P}$", "u"),
    "S (Symbol)": window.RegExp.new(r"^\p{S}$", "u"),
    "Z (Separator)": window.RegExp.new(r"^\p{Z}$", "u"),
    "C (Other)": window.RegExp.new(r"^\p{C}$", "u")
}

# Aliases for the "Full Breakdown" (Tier 3) tab
ALIASES = {
    "Lu": "Uppercase Letter", "Ll": "Lowercase Letter", "Lt": "Titlecase Letter", "Lm": "Modifier Letter", "Lo": "Other Letter",
    "Mn": "Nonspacing Mark", "Mc": "Spacing Mark", "Me": "Enclosing Mark",
    "Nd": "Decimal Number", "Nl": "Letter Number", "No": "Other Number",
    "Pc": "Connector Punct.", "Pd": "Dash Punct.", "Ps": "Open Punct.", "Pe": "Close Punct.", 
    "Pi": "Initial Punct.", "Pf": "Final Punct.", "Po": "Other Punct.",
    "Sm": "Math Symbol", "Sc": "Currency Symbol", "Sk": "Modifier Symbol", "So": "Other Symbol",
    "Zs": "Space Separator", "Zl": "Line Separator", "Zp": "Paragraph Separator",
    "Cc": "Control", "Cf": "Format", "Cs": "Surrogate", "Co": "Private Use", "Cn": "Unassigned"
}

# --- 2. CREATE JS REGEXP OBJECTS (for performance) ---

# Compilers for Module 1 (Character Analysis)
# RE_MINOR is now RE_MINOR_LEGACY (all 30, for Module 2 and Legacy Mode)
RE_MINOR_LEGACY = {key: window.RegExp.new(val, "gu") for key, val in MINOR_CATEGORIES.items()}
# NEW: A 29-category dict for "Honest" mode (all *except* 'Cn')
RE_MINOR_29_HONEST = {k: v for k, v in RE_MINOR_LEGACY.items() if k != "Cn"}

RE_DERIVED = {key: window.RegExp.new(val, "gv") for key, val in DERIVED_PROPERTIES.items()} 
RE_SCRIPTS = {key: window.RegExp.new(val, "gu") for key, val in SCRIPTS.items()}

# NEW: Compilers for Forensic Module
RE_FORENSIC = {
    # These can be 'gu' for simple global counting
    "Bidi Controls": window.RegExp.new(FORENSIC_PROPERTIES["Bidi Controls"], "gu"),
    "Deprecated": window.RegExp.new(FORENSIC_PROPERTIES["Deprecated"], "gu"),             # <-- NEW
    "Noncharacter": window.RegExp.new(FORENSIC_PROPERTIES["Noncharacter"], "gu"),         # <-- NEW
    "Ignorables (Invisible)": window.RegExp.new(FORENSIC_PROPERTIES["Ignorables (Invisible)"], "gu"),
    # This one MUST use 'gv' (global, v-flag) for the set operation
    "Deceptive Spaces": window.RegExp.new(FORENSIC_PROPERTIES["Deceptive Spaces"], "gv")
}

# NEW: Compilers for UAX #44 Module
RE_UAX44 = {
    key: window.RegExp.new(val, "gu") 
    for key, val in UAX44_PROPERTIES.items()
}

# NEW: Counter for Grapheme Forensics (counts \p{M})
RE_MARK_COUNTER = window.RegExp.new(r"\p{M}", "gu")
    
# Testers for Module 2 (Token Shape Analysis)
TEST_MINOR = {key: window.RegExp.new(f"^{val}$", "u") for key, val in MINOR_CATEGORIES.items()}

# NEW: Helpers for Security Module
# Finds all continuous runs of one or more letters
RE_LETTER_RUNS = window.RegExp.new(r"\p{L}+", "gu")

# Tests if a string contains at least one Latin-script character
RE_TEST_LATIN = window.RegExp.new(r"\p{sc=Latin}", "u")

# Tests if a string contains at least one Letter that is *not* Latin
# Uses the 'v' flag for Unicode set operations: [\p{L} (all letters) AND \P{sc=Latin} (not Latin)]
RE_TEST_NOT_LATIN = window.RegExp.new(r"[\p{L}&&\P{sc=Latin}]", "v")

# NEW: Grapheme Segmenter (Module 1 alternate)
# We create one segmenter instance to reuse
GRAPHEME_SEGMENTER = window.Intl.Segmenter.new("en", {"granularity": "grapheme"})
    
# --- 3. HELPER FUNCTIONS ---

def count_matches(regex, text):
    """Counts matches of a JS RegExp object in a string."""
    # We must explicitly call the JS String.prototype.match method
    # and pass the Python string 'text' as the 'this' context.
    matches = window.String.prototype.match.call(text, regex)
    return len(matches) if matches else 0

def get_char_type(char, is_minor):
    """Classifies a single char as a Major or Minor category."""
    if is_minor:
        for key, regex in TEST_MINOR.items():
            if regex.test(char):
                return key
    else:
        for key, regex in MAJOR_CATEGORIES_TEST.items():
            if regex.test(char):
                return key
    return "NONE"

def get_state():
    """Gets the UI state from the hidden div."""
    try:
        return json.loads(document.getElementById("app-state").innerHTML)
    except:
        return {"active_tab": "summary"} # Default state

def set_state(key, value):
    """Sets a value in the UI state."""
    state = get_state()
    state[key] = value
    document.getElementById("app-state").innerHTML = json.dumps(state)

# --- 4. CORE LOGIC (MODULES) ---

def compute_comprehensive_stats(t: str, is_honest_mode: bool):
        """Module 1: Runs the 3-Tier analysis."""
# --- PASS 1: Count DERIVED Properties (Tier 1) ---
    # This is now common to both modes
        code_points_array = window.Array.from_(t)
        derived_stats = {
    "Total Code Points": len(code_points_array),
    "RGI Emoji Sequences": count_matches(RE_DERIVED["Emoji"], t),
    "Whitespace (Total)": count_matches(RE_DERIVED["Whitespace"], t)
    }

        minor_stats = {}

        if is_honest_mode:
        # --- HONEST MODE (Fixes 1 & 2) ---
        # 1. Count 29 categories against the FULL text (no emoji deletion)
            for key, regex in RE_MINOR_29_HONEST.items():
                minor_stats[key] = count_matches(regex, t)
        # 2. Calculate 'Cn' as the mathematical remainder
            sum_of_29_cats = sum(minor_stats.values())
            total_code_points = derived_stats["Total Code Points"]
            cn_count = total_code_points - sum_of_29_cats
            minor_stats["Cn"] = cn_count
        else:
        # --- LEGACY (FILTERED) MODE ---
        # 1. Keep the original flawed logic (delete emoji)
            text_no_emoji = window.String.prototype.replace.call(t, RE_DERIVED["Emoji"], "")
        # 2. Count all 30 categories (incl. flawed \p{Cn}) against the filtered text
            for key, regex in RE_MINOR_LEGACY.items():
                minor_stats[key] = count_matches(regex, text_no_emoji)
   # --- PASS 3: Aggregate MAJOR Categories (Tier 2) ---
        # This logic is UNCHANGED. It correctly aggregates 'minor_stats'
        # from whichever mode was run.
        major_stats = {
        "L (Letter)": minor_stats["Lu"] + minor_stats["Ll"] + minor_stats["Lt"] + minor_stats["Lm"] + minor_stats["Lo"],
        "M (Mark)": minor_stats["Mn"] + minor_stats["Mc"] + minor_stats["Me"],
        "N (Number)": minor_stats["Nd"] + minor_stats["Nl"] + minor_stats["No"],
        "P (Punctuation)": minor_stats["Pc"] + minor_stats["Pd"] + minor_stats["Ps"] + minor_stats["Pe"] + minor_stats["Pi"] + minor_stats["Pf"] + minor_stats["Po"],
        "S (Symbol)": minor_stats["Sm"] + minor_stats["Sc"] + minor_stats["Sk"] + minor_stats["So"],
        "Z (Separator)": minor_stats["Zs"] + minor_stats["Zl"] + minor_stats["Zp"],
        "C (Other)": minor_stats["Cc"] + minor_stats["Cf"] + minor_stats["Cs"] + minor_stats["Co"] + minor_stats["Cn"]
        }

        # --- Build Summary (Tier 1) ---
        # This logic is UNCHANGED.
        summary_stats = {
        "Total Code Points": derived_stats["Total Code Points"],
        "RGI Emoji Sequences": derived_stats["RGI Emoji Sequences"],
        "Whitespace (Total)": derived_stats["Whitespace (Total)"],
        "L (Letter)": major_stats["L (Letter)"],
        "N (Number)": major_stats["N (Number)"],
        "P (Punctuation)": major_stats["P (Punctuation)"],
        "S (Symbol)": major_stats["S (Symbol)"]
        }

        return summary_stats, major_stats, minor_stats

def compute_sequence_stats(t: str, is_minor: bool):
    """Module 2: Runs the Token Shape Analysis."""
    if is_minor:
        counters = {key: 0 for key in MINOR_CATEGORIES}
    else:
        counters = {key: 0 for key in MAJOR_CATEGORIES_TEST}
    
    if not t:
        return counters

    current_state = "NONE"
    
    for char in t:
        new_state = get_char_type(char, is_minor)
        
        if new_state != current_state:
            if current_state in counters:
                counters[current_state] += 1
            current_state = new_state
            
    if current_state in counters:
        counters[current_state] += 1
        
    return counters

def compute_script_stats(t: str, is_honest_mode: bool):
    """Module 3: Runs the Script Analysis."""
    
    text_to_scan = t # Default to Honest mode

    if not is_honest_mode:
    # Legacy (Filtered) mode: remove emoji first
        text_to_scan = window.String.prototype.replace.call(t, RE_DERIVED["Emoji"], "")
    
    script_stats = {}
    sum_of_known_scripts = 0

    # 1. Count the known scripts (Latin, Common, Inherited)
    for key, regex in RE_SCRIPTS.items():
        count = count_matches(regex, text_to_scan)
        script_stats[key] = count
        sum_of_known_scripts += count

    # 2. Get the total code points *of the text we just scanned*
    # This is the key to the "Honest" partition
    total_code_points_in_scan = len(window.Array.from_(text_to_scan))

    # 3. Calculate "Other" as the mathematical remainder
    other_count = total_code_points_in_scan - sum_of_known_scripts
    script_stats["Other"] = other_count
    
    return script_stats

def compute_grapheme_stats(t: str):
    """Module 1 (Alternate): Runs the 3-Tier analysis AND
       Module 1.5: Grapheme Forensics."""
    
    # --- PASS 1: Get all grapheme segments ---
    segments_iterable = GRAPHEME_SEGMENTER.segment(t)
    segments = window.Array.from_(segments_iterable)
    
    total_graphemes = len(segments)
    
    # Initialize counters for Module 1
    minor_stats = {key: 0 for key in MINOR_CATEGORIES}

    # Initialize counters for Module 1.5 (Forensics)
    single_cp_count = 0
    multi_cp_count = 0
    total_mark_count = 0
    max_marks = 0

    # --- PASS 2: Classify and Analyze each grapheme ---
    for segment in segments:
        grapheme_str = segment.segment
        
        if not grapheme_str:
            continue

        # --- Module 1.5 Logic (Forensics) ---
        cp_array = window.Array.from_(grapheme_str)
        cp_count = len(cp_array)

        if cp_count == 1:
            single_cp_count += 1
        elif cp_count > 1:
            multi_cp_count += 1
        
        mark_count = count_matches(RE_MARK_COUNTER, grapheme_str)
        total_mark_count += mark_count
        if mark_count > max_marks:
            max_marks = mark_count

        # --- Module 1 Logic (Classification) ---
        first_char = cp_array[0]
        
        classified = False
        for key, regex in TEST_MINOR.items():
            if regex.test(first_char):
                minor_stats[key] += 1
                classified = True
                break
        
        if not classified:
            minor_stats["Cn"] += 1

    # --- PASS 3: Aggregate MAJOR Categories (Tier 2) ---
    major_stats = {
        "L (Letter)": minor_stats["Lu"] + minor_stats["Ll"] + minor_stats["Lt"] + minor_stats["Lm"] + minor_stats["Lo"],
        "M (Mark)": minor_stats["Mn"] + minor_stats["Mc"] + minor_stats["Me"],
        "N (Number)": minor_stats["Nd"] + minor_stats["Nl"] + minor_stats["No"],
        "P (Punctuation)": minor_stats["Pc"] + minor_stats["Pd"] + minor_stats["Ps"] + minor_stats["Pe"] + minor_stats["Pi"] + minor_stats["Pf"] + minor_stats["Po"],
        "S (Symbol)": minor_stats["Sm"] + minor_stats["Sc"] + minor_stats["Sk"] + minor_stats["So"],
        "Z (Separator)": minor_stats["Zs"] + minor_stats["Zl"] + minor_stats["Zp"],
        "C (Other)": minor_stats["Cc"] + minor_stats["Cf"] + minor_stats["Cs"] + minor_stats["Co"] + minor_stats["Cn"]
    }

    # --- Build Summary (Tier 1) ---
    summary_stats = {
        "Total Graphemes": total_graphemes,
        "L (Letter)": major_stats["L (Letter)"],
        "N (Number)": major_stats["N (Number)"],
        "P (Punctuation)": major_stats["P (Punctuation)"],
        "S (Symbol)": major_stats["S (Symbol)"]
    }

    # --- PASS 4: Build Grapheme Forensics (Module 1.5) ---
    avg_marks = (total_mark_count / total_graphemes) if total_graphemes > 0 else 0
    
    grapheme_forensic_stats = {
        "Total Graphemes": total_graphemes,
        "Single-Code-Point": single_cp_count,
        "Multi-Code-Point": multi_cp_count,
        "Total Combining Marks": total_mark_count,
        "Max Marks in one Grapheme": max_marks, # (Zalgo Detector)
        "Avg. Marks per Grapheme": round(avg_marks, 2)
    }

    # Return all 4 data packages
    return summary_stats, major_stats, minor_stats, grapheme_forensic_stats
    
def compute_security_stats(t: str, is_honest_mode: bool):
    """Module 3 Add-on: Runs the Mixed-Script Run security check."""
    
    text_to_scan = t # Default to Honest mode

    if not is_honest_mode:
        # Legacy (Filtered) mode: remove emoji first
        # We must use the global RE_DERIVED object here
        text_to_scan = window.String.prototype.replace.call(t, RE_DERIVED["Emoji"], "")
    
    if not text_to_scan:
        return {"Mixed-Script Runs": 0}

    mixed_run_count = 0
    
    # Use the global regex to find all continuous runs of letters
    letter_runs = window.String.prototype.match.call(text_to_scan, RE_LETTER_RUNS)
    
    if not letter_runs:
        # No letter runs found in the text
        return {"Mixed-Script Runs": 0}

    # Analyze each letter-run individually
    for run in letter_runs:
        # Test if this specific run contains at least one Latin char
        has_latin = RE_TEST_LATIN.test(run)
        
        # Test if this specific run contains at least one non-Latin *letter*
        # This prevents runs of 'Hello!!!' from being flagged if '!' is not 'sc=Latin'
        has_not_latin_letter = RE_TEST_NOT_LATIN.test(run)
        
        # If a single, continuous run of letters has both, it's a "Mixed-Script Run"
        if has_latin and has_not_latin_letter:
            mixed_run_count += 1
            
    return {"Mixed-Script Runs": mixed_run_count}

# NEW: FORENSIC ANALYSIS FUNCTION
def compute_forensic_stats(t: str, is_honest_mode: bool, minor_stats: dict):
    """Module 3 Add-on: Runs the Forensic Analysis."""
    
    text_to_scan = t # Default to Honest mode

    if not is_honest_mode:
        # Legacy (Filtered) mode: remove emoji first
        text_to_scan = window.String.prototype.replace.call(t, RE_DERIVED["Emoji"], "")
    
    # 1. Initialize with the pre-calculated counts from Module 1
    #    This is efficient and respects "Honest Mode" logic for Cn.
    forensic_stats = {
        # Get counts from minor_stats, defaulting to 0
        "Unassigned (Void)": minor_stats.get("Cn", 0),
        "Surrogates (Broken)": minor_stats.get("Cs", 0),
        "Private Use (Black Box)": minor_stats.get("Co", 0),
        "Control (Cc)": minor_stats.get("Cc", 0)  # <-- PROMOTED FLAG
    }

    # 2. Run the other regex-based forensic checks
    for key, regex in RE_FORENSIC.items():
        forensic_stats[key] = count_matches(regex, text_to_scan)

    return forensic_stats

# NEW: UAX #44 ANALYSIS FUNCTION
def compute_uax44_stats(t: str, is_honest_mode: bool):
    """Module 5: Runs the UAX #44 Property Analysis."""
    
    text_to_scan = t # Default to Honest mode

    if not is_honest_mode:
        # Legacy (Filtered) mode: remove emoji first
        text_to_scan = window.String.prototype.replace.call(t, RE_DERIVED["Emoji"], "")
    
    uax44_stats = {}

    for key, regex in RE_UAX44.items():
        uax44_stats[key] = count_matches(regex, text_to_scan)

    return uax44_stats

# NEW: UCD DEEP SCAN FUNCTION (PYTHON)
def compute_ucd_deep_scan(t: str, is_honest_mode: bool):
    """Module 6: Runs a Python-based deep scan for properties
       not available in RegExp."""
    
    text_to_scan = t # Default to Honest mode

    if not is_honest_mode:
        # Legacy (Filtered) mode: remove emoji first
        text_to_scan = window.String.prototype.replace.call(t, RE_DERIVED["Emoji"], "")
    
    numeric_type_stats = {}
    numeric_total_value = 0

    # Iterate through every code point in Python
    for char in text_to_scan:
        
        # --- 1. Get Age ---
        # try:
            # Get the Unicode version string, e.g., "1.1", "5.0", "13.0"
          #   age = unicodedata.age(char)
          #   age_key = f"Age: {age}"
          #   age_stats[age_key] = age_stats.get(age_key, 0) + 1
      #   except ValueError:
        #     pass # Not all chars have an age

        # --- 2. Get Numeric Properties ---
        try:
            # This throws an error if the char is not numeric
            value = unicodedata.numeric(char) 
            numeric_total_value += value
            
            # Get the General_Category as a proxy for Numeric_Type
            gc = unicodedata.category(char)
            if gc == "Nd": n_type = "Num Type: Decimal (Nd)"
            elif gc == "Nl": n_type = "Num Type: Letter (Nl)"
            elif gc == "No": n_type = "Num Type: Other (No)"
            else: n_type = f"Num Type: Other ({gc})"
            
            numeric_type_stats[n_type] = numeric_type_stats.get(n_type, 0) + 1
            
        except (ValueError, TypeError):
            pass # Not a numeric character

    # Round the total value to avoid floating point issues
    final_total_value = round(numeric_total_value, 4)
    
    return numeric_type_stats, final_total_value

# --- 5. DOM/UI FUNCTIONS ---

def render_stats(stats_dict, element_id, class_name="card"):
    """Generates and injects HTML for standard stat cards."""
    html = []
    for k, v in stats_dict.items():
        if v > 0:
            html.append(f'<div class="{class_name}"><strong>{k}</strong><div>{v}</div></div>')
    
    element = document.getElementById(element_id)
    if element:
        element.innerHTML = "".join(html) if html else "<p style='padding: 1rem; color: #6b7280;'>No data for this category.</p>"

def render_minor_stats(stats_dict, element_id):
    """Generates and injects HTML for the 30-category breakdown."""
    html = []
    for k, v in stats_dict.items():
        if v > 0:
            alias = ALIASES.get(k, "Unknown")
            html.append(f'<div class="minor-card"><div class="minor-key">{k}</div><div class="minor-alias" title="{alias}">{alias}</div><div class="minor-val">{v}</div></div>')
    
    element = document.getElementById(element_id)
    if element:
        element.innerHTML = "".join(html) if html else "<p style='padding: 1rem; color: #6b7280;'>No data for this category.</p>"

def _select_tab_internal(tab_name):
    """Internal logic for switching tabs."""
    # Store state
    set_state("active_tab", tab_name)
    
    # Update button active class
    for btn in document.querySelectorAll(".tab-btn"):
        btn.classList.remove("active")
    document.getElementById(f"tab-btn-{tab_name}").classList.add("active")
    
    # Update content active class
    for content in document.querySelectorAll(".tab-content"):
        content.classList.remove("active")
    document.getElementById(f"tab-{tab_name}").classList.add("active")

# This is the new event handler for py-click
@create_proxy
def select_tab(event):
    """Handles tab switching UI from a JS click event."""
    # Get tab name from the button's ID
    # e.g., id="tab-btn-summary" -> "summary"
    tab_name = event.target.id.split('-')[-1]
    _select_tab_internal(tab_name)


# --- 6. MAIN ENTRY POINT ---

def update_all(event=None):
    """The main function called on every keypress."""
    t = document.getElementById("text").value

    # Read UI state
    is_minor_seq = document.getElementById("granularity-toggle").checked
    is_honest_mode = document.getElementById("analysis-mode-toggle").checked
    is_grapheme_mode = document.getElementById("unit-mode-toggle").checked
    active_tab = get_state()["active_tab"]

    # Get references to all modules
    module_2_header = document.getElementById("module-2-header")
    module_2_content = document.getElementById("sequence-stats")
    module_2_toggle = document.getElementById("granularity-toggle").parentElement
    
    module_3_header = document.getElementById("module-3-header")
    module_3_content = document.getElementById("script-stats")
    
    module_4_header = document.getElementById("module-4-header")
    module_4_content = document.getElementById("forensic-stats")
    
    module_5_header = document.getElementById("module-5-header")
    module_5_content = document.getElementById("uax44-stats")
    
    module_6_header = document.getElementById("module-6-header")
    module_6_content = document.getElementById("ucd-deep-scan-stats")
    
    grapheme_forensics_module = document.getElementById("grapheme-forensics-module")

    # --- Module 1 Toggle ---
    if is_grapheme_mode:
        # 1. Run compute function (now returns 4 items)
        summary_stats, major_stats, minor_stats, g_forensics = compute_grapheme_stats(t)
        
        # 2. Render Module 1 (the 3 tabs)
        render_stats(summary_stats, "tab-summary")
        render_stats(major_stats, "tab-major")
        render_minor_stats(minor_stats, "tab-minor")
        
        # 3. Show Module 1.5 (Grapheme Forensics)
        grapheme_forensics_module.style.display = "block"
        render_stats(g_forensics, "grapheme-forensics-stats", class_name="card")

        # --- HIDE OTHER MODULES ---
        document.getElementById("analysis-mode-toggle").disabled = True
        module_2_header.style.display = "none"
        module_2_content.style.display = "none"
        module_2_toggle.parentElement.style.display = "none"
        module_3_header.style.display = "none"
        module_3_content.style.display = "none"
        module_4_header.style.display = "none"
        module_4_content.style.display = "none"
        module_5_header.style.display = "none"
        module_5_content.style.display = "none"
        module_6_header.style.display = "none"
        module_6_content.style.display = "none"
    
    else:
        # --- HIDE GRAPHEME FORENSICS ---
        grapheme_forensics_module.style.display = "none"

        # --- SHOW OTHER MODULES ---
        document.getElementById("analysis-mode-toggle").disabled = False
        module_2_header.style.display = "flex"
        module_2_content.style.display = "grid"
        module_2_toggle.parentElement.style.display = "flex"
        module_3_header.style.display = "flex"
        module_3_content.style.display = "grid"
        module_4_header.style.display = "flex"
        module_4_content.style.display = "grid"
        module_5_header.style.display = "flex"
        module_5_content.style.display = "grid"
        module_6_header.style.display = "flex"
        module_6_content.style.display = "grid"
        
        # --- Original Code Path ---
        summary_stats, major_stats, minor_stats = compute_comprehensive_stats(t, is_honest_mode)

    # Render Module 1 (Always runs, just with different data)
    render_stats(summary_stats, "tab-summary")
    render_stats(major_stats, "tab-major")
    render_minor_stats(minor_stats, "tab-minor")

    # --- Run Modules 2-6 (Only if not in Grapheme mode) ---
    if not is_grapheme_mode:
        t = document.getElementById("text").value # Re-get text
        
        # Run Module 2
        seq_stats = compute_sequence_stats(t, is_minor_seq)
        render_stats(seq_stats, "sequence-stats")

        # Run Module 3 (Script & Security)
        script_stats = compute_script_stats(t, is_honest_mode)
        security_stats = compute_security_stats(t, is_honest_mode)
        combined_script_stats = {
            **security_stats, 
            **script_stats
        }
        render_stats(combined_script_stats, "script-stats", class_name="card")
        
        # Run Module 4 (Forensics)
        forensic_stats = compute_forensic_stats(
            t, is_honest_mode, minor_stats
        )
        render_stats(forensic_stats, "forensic-stats", class_name="card")
        
        # Run Module 5 (UAX #44)
        uax44_stats = compute_uax44_stats(t, is_honest_mode)
        render_stats(uax44_stats, "uax44-stats", class_name="card")

        # Run Module 6 (Python Deep Scan)
        numeric_types, total_value = compute_ucd_deep_scan(t, is_honest_mode)
        
        total_value_dict = {}
        if total_value > 0 or "Num Type: Decimal (Nd)" in numeric_types or "Num Type: Letter (Nl)" in numeric_types or "Num Type: Other (No)" in numeric_types:
            # Show total value even if it's 0, as long as there were numbers
            total_value_dict = {"Total Numeric Value": total_value}
            
        combined_deep_scan_stats = {
            **total_value_dict, 
            **numeric_types 
        }
        render_stats(combined_deep_scan_stats, "ucd-deep-scan-stats", class_name="card")

    # --- Final UI sync ---
    _select_tab_internal(active_tab)

# Initial call to populate the dashboard on load
update_all()

  </script>

</body>

</html>
